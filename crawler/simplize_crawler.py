import os
import pickle
import logging
import time
import pandas as pd
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, NoSuchElementException
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from webdriver_manager.chrome import ChromeDriverManager
from selenium_stealth import stealth

# Cáº¥u hÃ¬nh logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ÄÆ°á»ng dáº«n lÆ°u cookies
COOKIES_PATH = "cookies.pkl"

class SimplizeCrawler:
    def __init__(self, stock_code):
        self.stock_code = stock_code
        self.driver = None

    def initialize_driver(self):
        """Khá»Ÿi táº¡o trÃ¬nh duyá»‡t vá»›i Selenium Stealth"""
        options = Options()
        #options.add_argument("--headless")  # Cháº¡y áº©n náº¿u cáº§n
        options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/110.0.0.0 Safari/537.36")
        options.add_argument("--start-maximized")
        options.add_argument("--disable-blink-features=AutomationControlled")  # TrÃ¡nh bá»‹ phÃ¡t hiá»‡n lÃ  bot
        options.add_argument("--disable-gpu")
        options.add_argument("--no-sandbox")
        options.add_argument("--disable-dev-shm-usage")
        options.add_argument("start-maximized")
        options.add_argument("disable-infobars")
        options.add_argument("--disable-extensions")

        service = Service(ChromeDriverManager().install())
        self.driver = webdriver.Chrome(service=service, options=options)

        # KÃ­ch hoáº¡t Selenium Stealth Ä‘á»ƒ áº©n bot
        stealth(self.driver,
                languages=["en-US", "en"],
                vendor="Google Inc.",
                platform="Win32",
                webgl_vendor="Intel Inc.",
                renderer="Intel Iris OpenGL Engine",
                fix_hairline=True)

    def load_cookies(self):
        """Náº¡p cookies náº¿u cÃ³"""
        if os.path.exists(COOKIES_PATH):
            logger.info("ğŸª Äang táº£i cookies...")
            self.driver.get("https://simplize.vn/")  # Má»Ÿ trang chÃ­nh trÆ°á»›c khi náº¡p cookies
            time.sleep(3)
            with open(COOKIES_PATH, "rb") as file:
                cookies = pickle.load(file)
                for cookie in cookies:
                    self.driver.add_cookie(cookie)
            self.driver.refresh()
            time.sleep(3)
            logger.info("âœ… ÄÃ£ sá»­ dá»¥ng cookies Ä‘á»ƒ bá» qua Ä‘Äƒng nháº­p!")

            # Kiá»ƒm tra náº¿u cookies háº¿t háº¡n (trÃ¡nh lá»—i bá»‹ Ä‘Ã¡ ra ngoÃ i)
            if "ÄÄƒng nháº­p" in self.driver.page_source:
                logger.warning("ğŸ”‘ Cookies Ä‘Ã£ háº¿t háº¡n, cáº§n Ä‘Äƒng nháº­p láº¡i!")
                os.remove(COOKIES_PATH)
                self.login()

    def save_cookies(self):
        """LÆ°u cookies sau khi Ä‘Äƒng nháº­p"""
        with open(COOKIES_PATH, "wb") as file:
            pickle.dump(self.driver.get_cookies(), file)
        logger.info("ğŸ’¾ Cookies Ä‘Ã£ Ä‘Æ°á»£c lÆ°u!")

    def login(self):
        """YÃªu cáº§u ngÆ°á»i dÃ¹ng tá»± Ä‘Äƒng nháº­p vÃ  xÃ¡c minh CAPTCHA"""
        url = f"https://simplize.vn/co-phieu/{self.stock_code}/bao-cao"
        logger.info(f"ğŸ”„ Má»Ÿ trang Ä‘Äƒng nháº­p: {url}")
        self.driver.get(url)

        input("ğŸ›‘ Vui lÃ²ng Ä‘Äƒng nháº­p vÃ  xÃ¡c minh CAPTCHA, sau Ä‘Ã³ nháº¥n Enter Ä‘á»ƒ tiáº¿p tá»¥c...")

        # Sau khi ngÆ°á»i dÃ¹ng nháº­p tay xong, lÆ°u cookies Ä‘á»ƒ láº§n sau khÃ´ng cáº§n Ä‘Äƒng nháº­p láº¡i
        self.save_cookies()

    def crawl_data(self, num_rows=30, max_retries=3):
        """Thu tháº­p dá»¯ liá»‡u tá»« báº£ng bÃ¡o cÃ¡o"""
        url = f"https://simplize.vn/co-phieu/{self.stock_code}/bao-cao"
        logger.info(f"ğŸ“„ Äang thu tháº­p dá»¯ liá»‡u tá»«: {url}")
        self.driver.get(url)
        time.sleep(3)  # Äá»£i trang load

        data = []
        self.driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
        time.sleep(3)

        retry_count = 0
        while retry_count < max_retries:
            try:
                WebDriverWait(self.driver, 10).until(
                    EC.presence_of_element_located((By.CSS_SELECTOR, "tbody.simplize-table-tbody"))
                )
                break  # ThoÃ¡t vÃ²ng láº·p náº¿u Ä‘Ã£ tÃ¬m tháº¥y dá»¯ liá»‡u
            except TimeoutException:
                retry_count += 1
                logger.warning(f"â³ Láº§n thá»­ {retry_count}/{max_retries} - ChÆ°a tÃ¬m tháº¥y báº£ng dá»¯ liá»‡u, thá»­ láº¡i...")
                time.sleep(3)

        if retry_count == max_retries:
            logger.error("âŒ KhÃ´ng tÃ¬m tháº¥y dá»¯ liá»‡u trong báº£ng sau nhiá»u láº§n thá»­!")
            return data

        rows = self.driver.find_elements(By.CSS_SELECTOR, "tbody.simplize-table-tbody tr.simplize-table-row")
        if not rows:
            logger.info("âš ï¸ KhÃ´ng cÃ³ dá»¯ liá»‡u trong báº£ng!")
            return data

        for index, row in enumerate(rows):
            tds = row.find_elements(By.TAG_NAME, "td")
            if len(tds) < 6:
                continue

            date = tds[0].text.strip()
            title = tds[1].text.strip()
            source = tds[2].text.strip()
            recommendation = tds[3].text.strip()
            price = tds[4].text.strip()

            # Láº¥y link táº£i vá» PDF
            pdf_link_download = ""
            try:
                pdf_element = tds[5].find_element(By.CSS_SELECTOR, "a.css-z8opiu")
                pdf_link_download = pdf_element.get_attribute("href") if pdf_element else ""
            except NoSuchElementException:
                logger.warning(f"âš ï¸ KhÃ´ng tÃ¬m tháº¥y link táº£i vá» á»Ÿ dÃ²ng {index + 1}")

            logger.info(f"ğŸ”— Link táº£i vá»: {pdf_link_download}")

            data.append({
                "NgÃ y": date,
                "TiÃªu Ä‘á»": title,
                "Nguá»“n": source,
                "Khuyáº¿n nghá»‹": recommendation,
                "GiÃ¡ má»¥c tiÃªu": price,
                "Táº£i vá»": pdf_link_download
            })

            if len(data) >= num_rows:
                break

        return data

    def close_driver(self):
        """ÄÃ³ng trÃ¬nh duyá»‡t."""
        if self.driver:
            self.driver.quit()

if __name__ == "__main__":
    stock_code = 'HPG'
    num_rows = 10

    crawler = SimplizeCrawler(stock_code)
    crawler.initialize_driver()

    if os.path.exists(COOKIES_PATH):
        crawler.load_cookies()
    else:
        crawler.login()

    data = crawler.crawl_data(num_rows=num_rows)
    crawler.close_driver()

    # Xuáº¥t dá»¯ liá»‡u
    if data:
        df = pd.DataFrame(data)
        df.to_csv("bao_cao.csv", index=False)
        print(df)
    else:
        print("âš ï¸ KhÃ´ng cÃ³ dá»¯ liá»‡u Ä‘á»ƒ xuáº¥t.")
